<!DOCTYPE html>
<html lang="zh-EN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UniMoE Audio site</title>
    <link rel="stylesheet" href="css/index.css">
    <script src="js/audio-player.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #fff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            font-size: 1.1rem;
        }

        /* 继承主页面的页头样式 */
        .navbar {
            position: sticky;
            top: 0;
            width: 100%;
            background: rgba(255, 255, 255, 0.9);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid rgba(220, 220, 220, 0.3);
            padding: 0.5rem 2rem;
            z-index: 1000;
            box-sizing: border-box;
        }

        .nav-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            max-width: 1200px;
            margin: 0 auto;
        }

        .nav-left .home-link {
            font-size: 1.2rem;
            font-weight: 600;
            color: #1a1a1a;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .nav-left .home-link:hover {
            color: #667eea;
        }

        .nav-right .github-link {
            color: #666;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .nav-right .github-link:hover {
            color: #333;
        }

        .main-content {
            flex: 1;
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            width: 100%;
            box-sizing: border-box;
        }

        .header {
            text-align: center;
            margin-bottom: 3rem;
            padding: 2rem 0;
            border-bottom: 2px solid #f0f0f0;
        }

        .header h1 {
            font-size: 3.5rem;
            color: #1a1a1a;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }

        .header p {
            font-size: 1.75rem;
            color: #666;
            font-weight: 300;
        }

        .back-button {
            position: fixed;
            top: 5rem;
            left: 2rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-decoration: none;
            border-radius: 25px;
            font-size: 0.9rem;
            z-index: 100;
            transition: transform 0.3s ease;
        }

        .back-button:hover {
            transform: translateY(-2px);
        }

        .blog-section {
            margin-bottom: 3rem;
        }

        .section-title {
            font-size: 2.25rem;
            color: #2c3e50;
            margin-bottom: 1.5rem;
            border-left: 4px solid #007bff;
            padding-left: 1rem;
        }

        .content-block {
            margin-bottom: 2rem;
            padding: 1.5rem;
            background: #f8f9fa;
            border-radius: 8px;
        }

        .content-block h3 {
            font-size: 1.75rem;
            color: #34495e;
            margin-bottom: 1rem;
        }

        .content-block p {
            margin-bottom: 1rem;
            text-align: justify;
            font-size: 1.1rem;
        }

        .media-container {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
            margin: 1.5rem 0;
            justify-content: center;
        }

        .media-item {
            flex: 1;
            min-width: 300px;
            max-width: 900px;
            text-align: center;
            margin: 0 auto;
        }

        .media-item img, .media-item video, .media-item audio {
            width: 100%;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        .icon-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(80px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }

        .icon-item {
            text-align: center;
            padding: 1rem;
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        .icon-item svg {
            width: 48px;
            height: 48px;
            margin-bottom: 0.5rem;
            fill: #007bff;
        }

        .code-block {
            background: #2d3748;
            color: #e2e8f0;
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1.5rem 0;
            font-family: 'Consolas', 'Monaco', monospace;
        }

        /* 视频播放器样式 */
        .video-player-mini {
            width: 80px;
            height: 60px;
            border-radius: 8px;
            background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
            cursor: pointer;
            transition: all 0.3s ease;
            position: relative;
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: center;
            border: none;
            box-shadow: 0 2px 6px rgba(255, 154, 158, 0.3);
        }

        .video-player-mini:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 12px rgba(255, 154, 158, 0.4);
        }

        .video-player-mini.clicked {
            background: linear-gradient(135deg, #ff6b9d 0%, #c44569 100%);
        }

        .video-player-mini .play-icon {
            color: white;
            font-size: 16px;
            line-height: 1;
            user-select: none;
        }

        .video-cell {
            text-align: center;
            padding: 0.5rem;
            vertical-align: middle;
        }

        @media (max-width: 768px) {
            body {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 2.5rem;
            }
            
            .back-button {
                position: relative;
                top: 0;
                left: 0;
                display: inline-block;
                margin-bottom: 1rem;
            }
        }

        /* Text to Music Framework - 3列布局 */
        .text-to-music-framework .tts-table {
            table-layout: fixed;
        }

        .text-to-music-framework .tts-table th:nth-child(1),
        .text-to-music-framework .tts-table td:nth-child(1) {
            width: 20%;
            text-align: center;
            font-weight: bold;
            background-color: #f8f9fa;
            padding: 15px;
        }

        .text-to-music-framework .tts-table th:nth-child(2),
        .text-to-music-framework .tts-table td:nth-child(2) {
            width: 50%;
            text-align: left;
            padding: 15px;
        }

        .text-to-music-framework .tts-table th:nth-child(3),
        .text-to-music-framework .tts-table td:nth-child(3) {
            width: 30%;
            text-align: center;
            padding: 15px;
        }
    </style>
</head>
<body>
    <!-- 继承主页面的页头 -->
    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="home.html" class="home-link">UniMoE-Audio</a>
            </div>
            <div class="nav-right">
                <a href="https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/tree/master/UniMoE-Audio" target="_blank" class="github-link">GitHub</a>
            </div>
        </div>
    </nav>
    
    <div class="main-content">
        <div class="header">
            <!-- <p>September 17, 2025  Announcement </p> -->
            <h1>Introduction to UniMoE-Audio</h1>
            <p>A Unified Speech and Music Generation with Dynamic-Capacity Mixture of Experts</p>
        </div>

    <div class="blog-section">
        <h2 class="section-title">UniMoE-Audio</h2>
        <p>
            <strong>UniMoE-Audio</strong> is a unified framework that seamlessly combines speech and music generation. 
            Powered by a novel <strong>dynamic-capacity Mixture-of-Experts</strong> design, it adapts intelligently to input complexity, 
            enabling high-fidelity voice and expressive music within a single model.
        </p>
        <br>
        <p>
            UniMoE-Audio introduces <strong>a dynamic-capacity routing mechanism</strong> based on Top-P sampling for adaptive expert allocation, 
            together with a hybrid expert design that separates domain-specific computation (dynamic experts) from universal representations (shared experts). 
            To address data imbalance and task conflicts, UniMoE-Audio adopts a structured three-stage training curriculum. 
            From <strong>voice cloning</strong> and <strong>text-to-speech (TTS)</strong> to <strong>text-to-music (T2M)</strong> and <strong>video-to-music (V2M)</strong>, 
            UniMoE-Audio supports diverse creative workflows. 
            Extensive experiments confirm its state-of-the-art performance and superior cross-task synergy, paving the way toward <strong>universal audio generation</strong>.
        </p>
        <br>
        <div class="media-container" id="fig1">
            <div class="media-item">
                <img src="img/abstract.png" alt="Performance of UniMoE-Audio" style="max-width: 100%; width: 1600px; height: auto; display: block; margin: 0 auto; border-radius: 8px; box-shadow: 0 4px 12px rgba(123, 179, 255, 0.15);">
                <p style="font-size: 0.9em; color: #666; margin-top: 0.5rem;">
                    Left: Our model overcomes the performance degradation of naive joint training, achieving synergistic gains. 
                    <br>
                    Right: It demonstrates competitive performance against leading models on comprehensive speech and music metrics.
                </p>
                <p><strong>Fig. 1</strong>Performance of UniMoE-Audio</p>
            </div>
        </div>
        <br>
        <p>
            On the left of <a href="#fig1">Fig. 1</a>, 
            comparison against specialized baselines reveals the failure of naive joint
            training, which causes a clear performance degradation on speech generation and more significant decline on music generation.
            The root of this problem lies in the divergent objectives of speech and music tasks as well as severe data imbalances, 
            which make naive joint training incapable of capturing their inherent complexity.
        </p>
        <br>
        <p>  
            In contrast, UniMoE-Audio yields synergistic gains across both tasks. 
            On radar charts in <a href="#fig1">Fig. 1</a>, UniMoE-Audio is shown achieving competitive performance against leading models on a wide array of speech (a) and music (b) metrics.
        </p>
        <br>
        <h3>
            A Novel Dynamic-capacity MoE for Mitigating Task Conflict
        </h3>
        <br>
        <p>
            To provide adaptive allocation of computational resources between simple and complex tasks, 
            the model's architectural core is a Transformer enhanced with <strong>Dynamic-Capacity</strong> Mixture-of-Experts (MoE) layers.
            The following <a href="#fig2">Fig. 2</a> shows the overall architecture of UniMoE-Audio.
        </p>
        <div class="media-container">
            <div class="media-item">
                <img src="img/AudioLLM_model-MoE.png" alt="UniMoE-Audio Structure" style="max-width: 90%; width: 1200px; height: auto; display: block; margin: 0 auto; border-radius: 8px; box-shadow: 0 4px 12px rgba(123, 179, 255, 0.15);">
                <p style="font-size: 0.9em; color: #666; margin-top: 0.5rem;">
                    Left: The UniMoE-Audio unified architecture for speech and music generation from multimodal conditions.
                    <br>
                    Right: The proposed Top-P routing strategy for dynamic expert allocation based on token complexity.
                </p>
                <p><strong>Fig. 2</strong>  UniMoE-Audio Structure</p>
            </div>
        </div>
    </div>
    <p>
        Crucially, we introduce <strong>a Top-P routing strategy</strong> that overcomes the limitations of conventional static Top-K routing. 
        Instead of assigning a fixed number of experts to every token, 
        our approach dynamically determines the number of experts based on the complexity of each token.
        This ensures that simple tokens do not consume unnecessary resources, 
        while complex tokens are granted sufficient processing power, resulting in improved overall efficiency and performance.
    </p>
    <br>
    <p>
        Moreover, we employ <strong>a three-stage training curriculum</strong> to enable effective joint learning from imbalanced data. This process—comprising independent specialist training, integration with warm-up, and synergistic joint training—successfully overcomes the challenges of data imbalance and task conflict. (Details can be found in the paper)
        <!-- <a href="https://arxiv.org/abs/2310.17223">paper</a> -->
    </p> 
    <br>

    <div class = "blog-section">
        <h2 class="section-title">Experiment Results</h2>
        <p>
            We evaluate UniMoE-Audio against state-of-the-art specialized models for speech and music generation. 
            The results, summarized in Table 1, Table 2 and Table 3, demonstrate that
            our single, unified model not only <strong> avoids the performance degradation </strong> typical of naive joint training 
            but achieves competitive or even superior results in both domains.
        </p> 
        <style>
            .table-container {
                max-width: 1200px;
                margin: 2rem auto;
                overflow-x: auto;
                border: 1px solid #e0e0e0;
            }
            .research-table {
                width: 100%;
                border-collapse: collapse;
                white-space: nowrap;
                margin: 0 auto;
                min-width: 800px;
            }
            .research-table caption {
                padding: 10px;
                font-weight: bold;
                font-size: 1.1em;
                color: #333;
            }
            .research-table th, .research-table td {
                padding: 12px 15px;
                text-align: center;
                border: none;
            }
            .research-table thead {
                border-top: 2px solid #333;
                border-bottom: 1px solid #333;
            }
            .research-table thead tr:last-child {
                border-bottom: 2px solid #333;
            }
            /* dataset separator for transposed tables */
            .research-table .dataset-sep {
                border-top: 2px solid #666;
            }
            .research-table tbody tr:last-child {
                border-bottom: 2px solid #333;
            }
            .research-table th {
                font-weight: bold;
                background-color: #f8f9fa;
            }
            .research-table td i {
                font-style: italic;
                color: #666;
            }
            .research-table td b {
                font-weight: bold;
                color: #000000;
                /* bk:#d32f2f; */
            }
            ::-webkit-scrollbar {
                height: 8px;
            }
            ::-webkit-scrollbar-track {
                background: #f1f1f1;
                border-radius: 4px;
            }
            ::-webkit-scrollbar-thumb {
                background: #888;
                border-radius: 4px;
            }
            ::-webkit-scrollbar-thumb:hover {
                background: #555;
            }
        </style>

        <br>
        <h3>Speech Synthesis</h3>
        <br>
        <p>
            Speech Synthesis (TTS) converts text into natural and fluent speech, focusing on clarity, naturalness, and speaker characteristics.

        </p>
        <div class="table-container">
            <table class="research-table">
                <caption>Table 1: Performance on Speech Synthesis</caption>
                <tr>
                <th rowspan="2">Method</th>
                <th colspan="3">SeedTTS-EN</th>
                <th colspan="3">SeedTTS-ZH</th>
                <th colspan="2">Librispeech</th>
                <th colspan="2">AISHELL-3</th>
                </tr>
                <tr>
                <th>WER↓</th><th>UTMOS↑</th><th>SIM↑</th>
                <th>CER↓</th><th>UTMOS↑</th><th>SIM↑</th>
                <th>WER↓</th><th>UTMOS↑</th>
                <th>CER↓</th><th>UTMOS↑</th>
                </tr>
                <tr>
                <td colspan="15" style="border-top: 2px solid #333; padding: 0; height: 2px;"></td>
                </tr>
                <tr>
                <td>UniAudio</td>
                <td>0.072</td><td>3.46</td><td>0.40</td>
                <td>-</td><td>-</td><td>-</td>
                <td>0.183</td><td>3.26</td>
                <td>-</td><td>-</td>
                </tr>
                <tr>
                <td>Mini-CPM-O-2.6</td>
                <td>0.034</td><td>3.49</td><td>0.36</td>
                <td>0.130</td><td>2.94</td><td>0.47</td>
                <td>0.111</td><td>3.76</td>
                <td>0.131</td><td>3.30</td>
                </tr>
                <tr>
                <td>Qwen-Omni</td>
                <td>0.021</td><td>4.16</td><td>-</td>
                <td>0.016</td><td>3.28</td><td>-</td>
                <td>0.076</td><td>4.19</td>
                <td>0.025</td><td>3.38</td>
                </tr>
                <tr>
                <td>Step-audio</td>
                <td>0.022</td><td>3.84</td><td>0.52</td>
                <td>0.010</td><td>3.23</td><td>0.62</td>
                <td>0.050</td><td>4.37</td>
                <td>0.027</td><td>3.69</td>
                </tr>
                <tr>
                <td colspan="15" style="border-top: 2px solid #333; padding: 0; height: 2px;"></td>
                </tr>
                <tr>
                <td><i>UniMoE-Audio</i></td>
                <td><b>0.019</b></td><td><b>4.36</b></td><td><b>0.56</b></td>
                <td><b>0.008</b></td><td><b>3.73</b></td><td><b>0.65</b></td>
                <td><b>0.044</b></td><td><b>4.23</b></td>
                <td><b>0.016</b></td><td><b>3.86</b></td>
                </tr>
            </table>
        </div>  
        <p>
            Across multilingual benchmarks including SeedTTS, LibriSpeech, and AISHELL-3, UniMoE-Audio leads across all metrics, with WER as low as 0.019 and UTMOS up to 4.36 (3.86 for Chinese), outperforming UniAudio, Qwen-Omni, and others. This indicates superior speech clarity, naturalness, and speaker consistency.
        </p> 
        
        
        <br>
        <h3>Text to Music Generation</h3>
        <br>
        <p>
            Text-to-Music Generation (T2M) transforms text descriptions into music clips, evaluating the model's ability to capture melody, rhythm, and atmosphere.
        </p>
        <br>
        <!-- <div class="table-container">
            <table class="research-table">
            <caption>Table 1: Performance on Music & Text-to-Music Generation</caption>
            <tr>
                <th rowspan="2">Dataset</th>
                <th rowspan="2">Task</th>
                <th rowspan="2">Metric</th>
                <th colspan="3">Model</th>
            </tr>
            <tr>
                <th><i>Dense (Single-Task)</i></th>
                <th><i>Dense (Multi-Task)</i></th>
                <th><i>MoE (Multi-Task)</i></th>
            </tr>
            <tr>
                <td rowspan="7">MusicCap</td>
                <td rowspan="7">T2M</td>
                <td>PCT</td>
                <td>4.70</td><td>5.52</td><td><b>5.59</b></td>
            </tr>
            <tr>
                <td>PQT</td>
                <td>7.29</td><td>6.70</td><td><b>7.73</b></td>
            </tr>
            <tr>
                <td>CE↑</td>
                <td>6.03</td><td>5.89</td><td><b>6.20</b></td>
            </tr>
            <tr>
                <td>CLAP↑</td>
                <td><b>0.308</b></td><td>0.290</td><td>0.293</td>
            </tr>
            <tr>
                <td>KL↓</td>
                <td>1.44</td><td>1.67</td><td><b>1.14</b></td>
            </tr>
            <tr>
                <td>CLaMP3↑</td>
                <td>0.120</td><td>0.108</td><td><b>0.138</b></td>
            </tr>
            <tr>
                <td>FAD↓</td>
                <td>3.72</td><td>2.53</td><td><b>0.92</b></td>
            </tr>
            <tr class="dataset-sep">
                <td rowspan="7">V2M-Bench</td>
                <td rowspan="7">T2M</td>
                <td>PCT</td>
                <td>4.41</td><td><b>5.69</b></td><td>5.60</td>
            </tr>
            <tr>
                <td>PQT</td>
                <td>7.46</td><td>6.69</td><td><b>7.98</b></td>
            </tr>
            <tr>
                <td>CE↑</td>
                <td>5.69</td><td>5.33</td><td><b>6.95</b></td>
            </tr>
            <tr>
                <td>CLAP↑</td>
                <td><b>0.345</b></td><td>0.328</td><td>0.264</td>
            </tr>
            <tr>
                <td>KL↓</td>
                <td>1.31</td><td>1.95</td><td><b>0.89</b></td>
            </tr>
            <tr>
                <td>CLaMP3↑</td>
                <td>0.163</td><td>0.153</td><td><b>0.187</b></td>
            </tr>
            <tr>
                <td>FAD↓</td>
                <td>2.94</td><td>1.73</td><td><b>1.13</b></td>
            </tr>
               </table>
        </div>

        <div class="table-container">
            <table class="research-table">
            <caption>Table 2: Performance on Speech Synthesis (SEED TTS)</caption>
            <tr>
                <th rowspan="2">Dataset</th>
                <th rowspan="2">Task</th>
                <th rowspan="2">Metric</th>
                <th colspan="3">Model</th>
            </tr>
            <tr>
                <th><i>Dense (Single-Task)</i></th>
                <th><i>Dense (Multi-Task)</i></th>
                <th><i>MoE (Multi-Task)</i></th>
            </tr>
            <tr>
                <td rowspan="6">Seed-TTS</td>
                <td rowspan="6">T2S</td>
                <td>WER% (EN)↓</td>
                <td>0.023</td><td>0.053</td><td><b>0.020</b></td>
            </tr>
            <tr>
                <td>MOS (EN)↑</td>
                <td>3.84</td><td>3.68</td><td><b>4.37</b></td>
            </tr>
            <tr>
                <td>SIM% (EN)↑</td>
                <td>0.533</td><td>0.511</td><td><b>0.586</b></td>
            </tr>
            <tr>
                <td>CER% (ZH)↓</td>
                <td>0.016</td><td>0.016</td><td><b>0.014</b></td>
            </tr>
            <tr>
                <td>MOS (ZH)↑</td>
                <td><b>3.23</b></td><td>3.20</td><td>3.32</td>
            </tr>
            <tr>
                <td>SIM% (ZH)↑</td>
                <td>0.620</td><td>0.572</td><td><b>0.694</b></td>
            </tr>
                </table>
        </div> -->
        <div class="table-container">
            <table class="research-table">
                <caption>Table 2: Performance of Text-to-Music Generation</caption>
                <tr>
                <th rowspan="2">Dataset</th>
                <th rowspan="2">Task</th>
                <th rowspan="2">Metric</th>
                <th colspan="6">Models</th>
                </tr>
                <tr>
                <th>YuE</th>
                <th>Stable Audio</th>
                <th>AudioX</th>
                <th>MuGen</th>
                <th>MUMU-LLAMA</th>
                <th><i>UniMoE-Audio</i></th>
                </tr>
                <tr>
                <td colspan="15" style="border-top: 2px solid #333; padding: 0; height: 2px;"></td>
                </tr>
                <!-- MusicCap -->
                <tr>
                <td rowspan="8">MusicCap</td>
                <td rowspan="8">T2M</td>
                <td>PC↑</td>
                <td>3.45</td><td>3.70</td><td>5.00</td><td>4.78</td><td>5.15</td><td><b>6.00</b></td>
                </tr>
                <tr>
                <td>PQ↑</td>
                <td>7.25</td><td>7.29</td><td>6.67</td><td>7.37</td><td>7.71</td><td><b>7.77</b></td>
                </tr>
                <tr>
                <td>CE↑</td>
                <td>5.84</td><td>6.02</td><td>6.14</td><td>6.57</td><td>6.87</td><td><b>7.34</b></td>
                </tr>
                <tr>
                <td>CLAP↑</td>
                <td>0.18</td><td><b>0.30</b></td><td>0.25</td><td>0.26</td><td>0.20</td><td>0.29</td>
                </tr>
                <tr>
                <td>KL↓</td>
                <td>2.12</td><td>1.44</td><td><b>1.20</b></td><td>1.21</td><td>1.27</td><td>1.39</td>
                </tr>
                <tr>
                <td>CLaMP3↑</td>
                <td>0.09</td><td>0.11</td><td><b>0.12</b></td><td>0.10</td><td>0.10</td><td><b>0.12</b></td>
                </tr>
                <tr>
                <td>IS↑</td>
                <td>2.09</td><td>2.74</td><td><b>3.02</b></td><td>1.68</td><td>1.44</td><td>1.93</td>
                </tr>
                <tr>
                <td>FAD↓</td>
                <td>9.02</td><td>3.72</td><td><b>1.64</b></td><td>7.02</td><td>8.57</td><td>6.43</td>
                </tr>
                <!-- V2M-bench -->
                <tr class="dataset-sep">
                <td rowspan="8">V2M-bench</td>
                <td rowspan="8">T2M</td>
                <td>PC↑</td>
                <td>3.78</td><td>3.41</td><td>4.60</td><td>4.64</td><td>5.19</td><td><b>5.75</b></td>
                </tr>
                <tr>
                <td>PQ↑</td>
                <td>7.25</td><td>7.46</td><td>7.30</td><td>7.37</td><td>7.73</td><td><b>7.58</b></td>
                </tr>
                <tr>
                <td>CE↑</td>
                <td>6.01</td><td>5.69</td><td>6.06</td><td>6.24</td><td>6.75</td><td><b>6.85</b></td>
                </tr>
                <tr>
                <td>CLAP↑</td>
                <td>0.15</td><td><b>0.34</b></td><td>0.30</td><td>0.28</td><td>0.17</td><td>0.31</td>
                </tr>
                <tr>
                <td>KL↓</td>
                <td>1.27</td><td>1.91</td><td>2.12</td><td>1.27</td><td><b>0.92</b></td><td>1.06</td>
                </tr>
                <tr>
                <td>CLaMP3↑</td>
                <td>0.13</td><td>0.16</td><td>0.11</td><td>0.15</td><td>0.13</td><td><b>0.19</b></td>
                </tr>
                <tr>
                <td>IS↑</td>
                <td>1.79</td><td>3.13</td><td><b>3.64</b></td><td>1.70</td><td>1.42</td><td>2.17</td>
                </tr>
                <tr>
                <td>FAD↓</td>
                <td>4.29</td><td>2.94</td><td>4.26</td><td>3.39</td><td><b>2.54</b></td><td>3.11</td>
                </tr>
            </table>
        </div>
        <p>
            On both MusicCap and V2M-bench, UniMoE-Audio achieves the best performance across key metrics such as PC, PQ, and CE (e.g., PC=6.00, PQ=7.77, CE=7.34 on MusicCap), outperforming strong baselines. This shows its ability to generate music with clear melody, coherent rhythm, and high perceptual quality.
        </p>


        <br>
        <h3>Video-Text to Music Generation</h3>
        <br>
        <p>
            Video-to-Music Generation (VT2M) generates music aligned with video content, testing cross-modal alignment and emotional expression.

        </p>
        <div class="table-container">
            <table class="research-table">
                <caption>Table 3: Performance of Video-Text-to-Music</caption>
                <tr>
                <th rowspan="2">Dataset</th>
                <th rowspan="2">Task</th>
                <th rowspan="2">Metric</th>
                <th colspan="2">Models</th>
                </tr>
                <tr>
                <th>AudioX</th>
                <th><i>UniMoE-Audio</i></th>
                </tr>
                <tr>
                <td colspan="5" style="border-top: 2px solid #333; padding: 0; height: 2px;"></td>
                </tr>
                <tr>
                <td rowspan="6">V2M-bench</td>
                <td rowspan="6">VT2M</td>
                <td>PC↑</td>
                <td>4.44</td><td><b>5.88</b></td>
                </tr>
                <tr>
                <td>PQ↑</td>
                <td>7.44</td><td><b>7.62</b></td>
                </tr>
                <tr>
                <td>CE↑</td>
                <td>6.06</td><td><b>6.96</b></td>
                </tr>
                <tr>
                <td>KL↓</td>
                <td>1.84</td><td><b>1.69</b></td>
                </tr>
                <tr>
                <td>IS↑</td>
                <td>3.14</td><td><b>3.31</b></td>
                </tr>
                <tr>
                <td>FAD↓</td>
                <td>2.94</td><td><b>2.89</b></td>
                </tr>
            </table>
        </div>
        <p>
            On V2M-bench, UniMoE-Audio significantly outperforms AudioX, reaching PC=5.88, PQ=7.62, and CE=6.96, while remaining competitive on diversity metrics like FAD. This demonstrates stronger capability in aligning video content with contextually fitting music, highlighting its cross-modal generation strength.
        </p>
        <br>

    <div class="blog-section">
        <h2 class="section-title">Performance</h2>
        <h3 style="text-align: center;">
            Speech Generation
        </h3>      
        <div class="tts-table-container">
            <table class="tts-table">
                <thead>
                    <tr>
                        <th><center>Speaker</center></th>
                        <th><center>Prompt Voice</center></th>
                        <th><center>Prompt Text</center></th>
                        <th><center>Target Text</center></th>
                        <th><center>Output Speech</center></th>
                    </tr>
                </thead>
                <tbody>
                                       <!-- 案例行 -->
                    <tr>
                        <td class="text-cell" rowspan="1">Male Chinese 1</td>
                        <td class="text-cell">夕阳慢慢沉下，城市的喧嚣逐渐远去，只剩下心跳和呼吸。我走在熟悉的街道，脚步与记忆轻轻相碰，像一首未完的歌。</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/p/prompt1.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">我们基于动态容量混合专家框架，构建了一个统一语音和音乐生成模型。</td>
                                 <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/g/audio1.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                                        <!-- 案例行 -->
                    <tr>
                        <td class="text-cell" rowspan="1">Male Chinese 1</td>
                        <td class="text-cell">生活是一场旅行，每一步都值得被记住。放慢脚步，嗅闻花香，听见自己的心声。勇敢走出去，你会遇见更大的世界。</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/p/prompt2.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">今夜星光闪闪，我爱你的心满满，想你一晚又一晚，把爱你的心都填满。</td>
                                 <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/g/audio2.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                                            <!-- 案例行 -->
                    <tr>
                        <td class="text-cell" rowspan="1">Male Chinese 2</td>
                        <td class="text-cell">知道曙光何时来，我打开每一扇门，是如鸟有羽，还是如岸有涛。</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/p/prompt6.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">有时候慢下来，认真感受生活，反而会发现更多的美好。</td>
                                 <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/g/audio6.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>

                                                   <!-- 案例行 -->
                    <tr>
                        <td class="text-cell" rowspan="1">Male Chinese 2</td>
                        <td class="text-cell">命无增无减，我们不再去留意时间，不再匆匆忙忙，宛若树木和星辰。</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/p/prompt5.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">哈尔滨工业大学历史悠久。新中国成立以来，在党的领导下，学校扎根东北、爱国奉献、艰苦创业，打造了一大批国之重器，培养了一大批杰出人才，为党和人民作出了重要贡献。</td>
                                 <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/g/audio5.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                  <!-- 案例行 -->
                    <tr>
                        <td class="text-cell" rowspan="1">Female Chinese 1</td>
                        <td class="text-cell">如果查尔斯继承王位，卡米拉将获得王后称号。</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/prompt_data/zh/female/prompt-wavs/00004859-00000009.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">机场工作人员和驻场武警，连夜在机场跑道上扫雪除冰。</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/vc/zh/cloned_voice_zh_female_0.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                      <!-- 案例行 -->
                    <tr>
                        <td class="text-cell" rowspan="1">Male English 1</td>
                        <td class="text-cell">This large sea duck is characterised by its bulky shape and large bill.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/prompt_data/en/male/prompt-wavs/common_voice_en_19656513.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">After this album was released, Steve Roach embarked on a second trip to Australia.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/vc/en/cloned_voice_en_male_0.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="text-cell" rowspan="1">Male English 2</td>
                        <td class="text-cell">We propose UniMoE-Audio, a unified speech and music generation model based on a novel dynamic-capacity Mixture-of-Experts framework.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/p/prompt4.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">The nature reserve covers only a small part of the marsh area.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/g/audio4.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="text-cell" rowspan="1">Male English 2</td>
                        <td class="text-cell">The nature reserve covers only a small part of the marsh area.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/p/prompt3.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">After this album was released, Steve Roach embarked on a second trip to Australia.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/g/audio3.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="text-cell" rowspan="1">Male English 3</td>
                        <td class="text-cell">My wars are laid away in books, I have one battle more, a foe whom I have never seen.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/p/prompt7.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">A hallmark of human intelligence is the seamless ability to perceive, reason, and create across multiple modalities, effortlessly blending language, vision, and audio.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/g/audio7.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                    <tr>
                        <td class="text-cell" rowspan="1">Male English 3</td>
                        <td class="text-cell">How happy is little stone that rambles in the road alone and don't care about carrers.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/p/prompt8.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">No matter how rough the road ahead is, keep moving and you will eventually see new horizons.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/audios_hit/g/audio8.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                       <!-- 案例行 -->
                    <!-- <tr>
                        <td class="text-cell" rowspan="1">Female English 1</td>
                        <td class="text-cell">The nature reserve covers only a small part of the marsh area.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/prompt_data/en/female/prompt-wavs/common_voice_en_18707936.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">Later, he expelled the Jews of Strassburg after a community debate.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/vc/en/cloned_voice_en_female_2.wav">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr> -->
                </tbody>
            </table>
        </div>

        <h3 style="text-align: center;">
            Music Generation
        </h3>      
        <div class="tts-table-container text-to-music-framework">
            <table class="tts-table">
                <thead>
                    <tr>
                        <th><center>Style</center></th>
                        <th><center>Style Description</center></th>
                        <th><center>Music</center></th>
                    </tr>
                </thead>
                <tbody>
                    <!-- 案例行 -->
                    <tr>
                        <td class="text-cell">Latin</td>
                        <td class="text-cell">This song contains several drum hits and percussive instruments playing a fast paced rhythm that motivates dancing along. An e-bass is bringing the low end supporting the drums. Cuatro guitars are strumming chords as a rhythmic addition. Trumpets are playing a loud and catchy melody. Some of the musical elements are slightly panned to the left and right side of the speakers. This song may be playing at a cheerful event.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/intro_music/demo_1.mp3">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                    <!-- 案例行 -->
                    <tr>
                        <td class="text-cell">Electronic</td>
                        <td class="text-cell">This song contains a digital drum playing a simple pattern with a kick and a snare sound. Synthesizers are playing a repeating melody in the higher register. Another synth sound is playing a more aggressive lead sound with a countermelody. A string sample is being used to create a short hit. This song may be playing during a car ride.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/intro_music/demo_2.mp3">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                        <!-- 案例行 -->
                    <tr>
                        <td class="text-cell">Electronic</td>
                        <td class="text-cell">This is a four on the floor style of production. The song is a drum and bass type of song with a bright and fuzzy synth to add a melodic element. The first part of the song feels suspenseful.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/intro_music/demo_3.mp3">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                                   <!-- 案例行 -->
                    <tr>
                        <td class="text-cell">Rock</td>
                        <td class="text-cell">This is a rock music piece. There is a medium-to-high pitched electric guitar solo at the forefront. In the melodic background, a keyboard and a bass guitar repeating the same pattern can be heard. The acoustic drums are playing a loud and slightly fast-paced rock drum beat. There is a rebellious atmosphere to this piece. It can be used in the soundtrack of a teenage drama or a crime shootout audio game.</td>
                        <td class="audio-cell">
                            <div class="audio-player-mini" data-audio="audios/intro_music/demo_4.mp3">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                </tbody>
            </table>
            <br>
            <table class="tts-table">
                <thead>
                    <tr>
                        <th><center>Prompt Video</center></th>
                        <th><center>Music Caption</center></th>
                        <th><center>Video with Music</center></th>
                    </tr>
                </thead>
                <tbody>
                    <!-- 案例行 -->
                    <tr>
                        <td class="video-cell">
                            <div class="video-player-mini" data-video="prompt_videos/grass.mp4">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">A calming instrumental piece featuring acoustic guitar, creating a peaceful and relaxing atmosphere. Ideal for meditation or background music.</td>
                        <td class="video-cell">
                            <div class="video-player-mini" data-video="VT2M/grass_with_music.mov">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                                        <!-- 案例行 -->
                    <tr>
                        <td class="video-cell">
                            <div class="video-player-mini" data-video="prompt_videos/humbug.mp4">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">This is an energetic funk instrumental driven by a catchy, clean electric guitar riff that creates an immediate sense of fun and groove. A tight, punchy drum beat and a driving, melodic bassline lock together to form an irresistible rhythmic foundation. The overall mood is upbeat, feel-good, and exciting, making it perfect for a fast-paced, dynamic video that showcases satisfying actions.</td>
                        <!-- 案例行 -->
                        <td class="video-cell">
                            <div class="video-player-mini" data-video="VT2M/humbug_with_music.mov">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                     <!-- 案例行 -->
                    <tr>
                        <td class="video-cell">
                            <div class="video-player-mini" data-video="prompt_videos/snowRider.mp4">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                        <td class="text-cell">A high-octane electronic piece, featuring pulsating synth chords and a powerful four-on-the-floor kick drum that creates a driving, relentless pace.</td>
                                            <!-- 案例行 -->
                        <td class="video-cell">
                            <div class="video-player-mini" data-video="VT2M/snowRider_with_music.mov">
                                <span class="play-icon">▶</span>
                            </div>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
    </div>

    <!-- 页脚 -->
    <footer class="footer">
        <div class="footer-content">
            <div class="footer-section">
                <div class="footer-links">
                    <div class="footer-icons">
                        <a href="https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs/tree/master/UniMoE-Audio" target="_blank" class="footer-link">
                            <svg viewBox="0 0 24 24" fill="currentColor">
                                <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                            </svg>
                        </a>
                        <a href="https://huggingface.co/foggyforest/UniMoE-Audio-preview" target="_blank" class="footer-link" title="Hugging Face">
                        <img src="img/hf-logo.png" alt="Hugging Face Logo" width="32" height="32" />
                        </a>
                    </div>
                    <div class="footer-copyright">
                        <p>© 2025 UniMoE-Audio. All rights reserved.</p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>
</html>